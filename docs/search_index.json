[["index.html", "STATS5099 Data Mining and Machine Learning 1 Welcome to DMML Lab 8 1.1 Implementing neural networks in R", " STATS5099 Data Mining and Machine Learning 1 Welcome to DMML Lab 8 In week 8, we have studied neural networks, which consists an input layer, an output layer and any number of hidden layers specified by the user. In this lab, we will see how to fit neural networks in R and Python. 1.1 Implementing neural networks in R To fit a relatively simple neural network (by simple, it means the network does not contain too many hidden layers, is not optimised using too advanced algorithms, and/or does not include regularisation techniques such as dropout), we use the neuralnet function from the neuralnet package. In particular, we need to specify the number of hidden layers and hidden nodes using the argument hidden, the loss function using err.fct, the activation function using act.fct, the activation function for the output layer using linear.output (set to TRUE for a linear activation function and FALSE to be the same as the activation function specified in act.fct). There are many other arguments could be manually set, such as the optimisation algorithm and learning rate; see help page of neuralnet for more details. library(neuralnet) # an example neural network for regression tasks Model &lt;- neuralnet(Y~X1+X2+..., data, hidden=c(5), err.fct=&quot;sse&quot;, act.fct=&quot;logistic&quot;, linear.output=TRUE) # The network contains a single hidden layers with 5 hidden nodes. # The network uses sum of squared errors as the loss function. # The network uses logistic function as the activation function for hidden nodes # and linear function as the activation function for output nodes. # an example neural network for classification tasks softplus &lt;- function(x) log(1+exp(x)) Model &lt;- neuralnet(Y~X1+X2+..., data, hidden=c(5,3), err.fct=&quot;ce&quot;, act.fct=softplus, linear.output=FALSE) # The network contains two hidden layers with 5 and 3 hidden nodes in each layer. # The network uses cross entropy as the loss function. # The network uses a user-defined softplus function as the activation function for hidden nodes and output nodes. # The softplus function is a smooth approximation to rectified linear unit (ReLU) function. To visualise the neural network, we could use the default plot function or plotnet function from the NeuralNetTools package. # option 1 plot(Model) # option 2 # library(devtools); install_github(&#39;fawda123/NeuralNetTools&#39;) library(NeuralNetTools) plotnet(Model) To use the model for predicting new observations, we could use the default predict function or the compute function. This returns the probability of the observation in each class and hence requires further conversion to evaluate the classification performance. # option 1 test_predict_prob&lt;- predict(model, test_data) # option 2 test_predict_prob&lt;- neuralnet::compute(model, test_data)$net.result # convert to class label for binary classification test_predict_class &lt;- ifelse(test_predict_prob&gt;0.5, class1, class2) #class 1 and class 2 are the class names # convert to class label for multi-class classification test_predict_class &lt;- apply(test_predict_prob, 1, which.max) "],["exercise-1-task-2-in-lecture-notes.html", "2 Exercise 1: Task 2 in lecture notes", " 2 Exercise 1: Task 2 in lecture notes QUESTION: On the Boston data, fit five neural networks such that the input layer has four nodes (crime.rate, low.socio.status, aver.rooms and river.bounds) the output layer has one node (median.value) one hidden layer with the logistic function as its activation function and different number of hidden nodes, specifically from 1 up to 5. For each neural network (i.e. the network with the specific number of hidden nodes), estimate the sum of squared errors (SSEs) for the training and test data sets. Visualise the SSEs with a graph and comment on its output. The following codes were included in the lecture note to pre-process the data and split the data into training and test sets. # load the data library(MASS) data(Boston) Boston &lt;- Boston[,c(&quot;medv&quot;,&quot;crim&quot;,&quot;lstat&quot;,&quot;rm&quot;,&quot;rad&quot;,&quot;chas&quot;)] colnames(Boston) &lt;- c(&quot;median.value&quot;,&quot;crime.rate&quot;,&quot;low.socio.status&quot;, &quot;aver.rooms&quot;,&quot;index.radial.highways&quot;,&quot;river.bounds&quot;) # min-max normalisation maxs &lt;- apply(Boston, 2, max) mins &lt;- apply(Boston, 2, min) scaled &lt;- as.data.frame(scale(Boston, center = mins, scale = maxs - mins)) # train-test random splitting set.seed(84) index &lt;- sample(1:nrow(Boston),round(0.75*nrow(Boston))) train_Boston&lt;- scaled[ index,] test_Boston &lt;- scaled[-index,] Hint: Write down the R command to fit a neural network on this dataset. Hint Suppose the hidden layer has only one hidden node. The corresponding R code is as follows. Model &lt;- neuralnet(median.value~crime.rate+low.socio.status+aver.rooms+river.bounds, data=train_Boston, hidden=c(1), linear.output=TRUE) Write down the R commands to calculate SSEs for the training and test data sets. Hint Slightly different from the usual formula for sum of squared errors, we divide it by two so that the formula is consistent with the neuralnet package: \\[\\frac{\\sum(\\text{observed}-\\text{fitted values})^2}{2}\\] # training SSEs train_SSE &lt;- sum((Model$net.result[[1]]-train_Boston$median.value)^2)/2 test_pred &lt;- neuralnet::compute(Model,test_Boston[,c(&quot;crime.rate&quot;, &quot;low.socio.status&quot;,&quot;aver.rooms&quot;)]) test_SSE &lt;- sum((test_pred$net.result[[1]]-test_Boston$median.value)^2)/2 Combining the two hints to solve the question. Solution library(neuralnet) set.seed(84) # create an empty dataframe to save training and test SSE. SSE &lt;- data.frame(matrix(nrow=5, ncol=3)) colnames(SSE) &lt;- c(&quot;no.hidden nodes&quot;,&quot;train SSE&quot;,&quot;test SSE&quot;) # train the neural network and record training and test SSE for (i in 1:5){ SSE[i,1] &lt;- i #record the number of hidden nodes nn_boston &lt;- neuralnet(median.value~crime.rate+low.socio.status+aver.rooms+river.bounds, data=train_Boston, hidden=c(i), linear.output=TRUE) #fit the model SSE[i,2] &lt;- sum((nn_boston$net.result[[1]] - train_Boston[,&quot;median.value&quot;])^2)/2 #record training SSE test_pred &lt;- neuralnet::compute(nn_boston, test_Boston[, c(&quot;crime.rate&quot;,&quot;low.socio.status&quot;,&quot;aver.rooms&quot;,&quot;river.bounds&quot;)]) SSE[i,3] &lt;- sum((test_pred$net.result[[1]] - test_Boston[, &quot;median.value&quot;])^2)/2 #record test SSE } SSE ## no.hidden nodes train SSE test SSE ## 1 1 2.128904 4.342257 ## 2 2 1.686398 3.460076 ## 3 3 1.488804 3.271197 ## 4 4 1.208661 3.345709 ## 5 5 1.201828 3.091838 To visualise the SSEs, we create a bar plot using ggplot. # Bar plot of results library(ggplot2);library(tibble) Regression_NN_Errors &lt;- tibble(Network = rep(c(&quot;NN1&quot;, &quot;NN2&quot;, &quot;NN3&quot;, &quot;NN4&quot;, &quot;NN5&quot;), each = 2), DataSet = rep(c(&quot;Train&quot;, &quot;Test&quot;), time = 5), SSE = c(t(SSE[,2:3]))) nn_ggplot &lt;- Regression_NN_Errors %&gt;% ggplot(aes(Network, SSE, fill = DataSet)) + geom_col(position = &quot;dodge&quot;) + ggtitle(&quot;Neural networks SSE (different number of nodes in the hidden layer)&quot;) nn_ggplot We can notice that: the training SSE is decreasing while the number of hidden nodes increases, and the test SSE is not monotonically decreasing and the lowest test SSE is achieved when the network has five nodes in the hidden layer. The first finding should not be surprising as adding more hidden nodes increases model capacity and hence the training error will decrease. However, a larger model may suffer from overfitting and hence the test error may not always decreasing. In general, we prefer the \"least\" complex neural network with the low(est) SSE on the test data set. Note that using different criteria could give us totally different results. In addition, be cautious that the current result is produced based on a single training of neural network. Since the optimisation of neural network is sensitive to initialisation, running the algorithm again is likely to lead to different conclusions. To alleviate such randomness, consider adding the argument rep into neuralnet; e.g. including rep=10 will force the same network to be trained for ten times. "],["exercise-2-german-data.html", "3 Exercise 2: German data", " 3 Exercise 2: German data This exercise extends Examples 6-8 in lecture note. Task Fit multiple neural networks with Account_balance, Purpose, Length_of_cur_employment and Credit_Amount as predictors in your model. Hide Remember to pre-process the data for both categorical variables and continuous variables before fitting the neural network. The categorical variables should be transformed into dummy variables using one-hot encoding and the continuous variables should be scaled using either standardisation or min-max normalisation. Compare the cross-entropy loss, Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) of different models, and select the optimal model. Hide To get AIC and BIC, set the argument likelihood=TRUE in neuralnet. For the optimal model you selected in part (2), report its test performance. Solution load(&quot;German.RData&quot;) train &lt;- German_train # Data pre-processing min_max_scale &lt;- function(x){ (x - min(x)) / (max(x) - min(x)) } train$Credit_amount &lt;- min_max_scale(train$Credit_amount) credit_card_matrix &lt;- model.matrix(~Account_balance+Purpose+Length_of_cur_employment +Credit_amount, data=train) credit_card_matrix_final &lt;- credit_card_matrix[,-1] Next we fit a few neural networks with different width (i.e. the number of hidden nodes) and depth (i.e. the number of hidden layers). train$Creditability &lt;- as.integer(train$Creditability)-1 predictor_list &lt;- paste(colnames(credit_card_matrix_final),collapse=&quot;+&quot;) f &lt;- paste(c(&quot;train$Creditability~&quot;,predictor_list),collapse=&quot;&quot;) set.seed(84) nn_credit_one_layer &lt;- neuralnet(f,data=credit_card_matrix_final,hidden=c(5), linear.output = FALSE,err.fct = &#39;ce&#39;, likelihood=TRUE, threshold = 0.1) nn_credit_two_layers_1 &lt;- neuralnet(f,data=credit_card_matrix_final, hidden=c(4,1), linear.output = FALSE,err.fct = &#39;ce&#39;, likelihood=TRUE, threshold = 0.1) nn_credit_two_layers_2 &lt;- neuralnet(f,data=credit_card_matrix_final, hidden=c(1,4), linear.output = FALSE,err.fct = &#39;ce&#39;, likelihood=TRUE, threshold = 0.1) nn_credit_two_layers_3 &lt;- neuralnet(f,data=credit_card_matrix_final, hidden=c(5,3), linear.output = FALSE,err.fct = &#39;ce&#39;, likelihood=TRUE, threshold = 0.1) Now we produce a bar plot comparing all built models. library(ggplot2); library(dplyr) Class_NN_ICs &lt;- tibble(&#39;Network&#39; = rep(c(&quot;NN_1L&quot;,&quot;NN_2L_1&quot;, &quot;NN_2L_2&quot;, &quot;NN_2L_3&quot;), each = 3), &#39;Metric&#39; = rep(c(&#39;AIC&#39;, &#39;BIC&#39;,&#39;CE loss&#39;), length.out=12), &#39;Value&#39; = c(nn_credit_one_layer$result.matrix[4,1], nn_credit_one_layer$result.matrix[5,1], nn_credit_one_layer$result.matrix[1,1], nn_credit_two_layers_1$result.matrix[4,1], nn_credit_two_layers_1$result.matrix[5,1], nn_credit_two_layers_1$result.matrix[1,1], nn_credit_two_layers_2$result.matrix[4,1], nn_credit_two_layers_2$result.matrix[5,1], nn_credit_two_layers_2$result.matrix[1,1], nn_credit_two_layers_3$result.matrix[4,1], nn_credit_two_layers_3$result.matrix[5,1], nn_credit_two_layers_3$result.matrix[1,1])) nn_ggplot &lt;- Class_NN_ICs %&gt;% ggplot(aes(Network, Value, fill=Metric)) + geom_col(position = &#39;dodge&#39;) + ggtitle(&quot;AIC, BIC, and cross entropy loss of the neural networks&quot;) nn_ggplot First recall that a smaller value of AIC and BIC indicates a better model. In terms of AIC the fourth neural network with 2 hidden layer and 5 and 3 nodes in each layer seemed to be best, while BIC preferred the second neural network with 2 hidden layers and 4 and 1 nodes in each layer. The cross entropy loss agreed with AIC so we would probably choose the fourth neural network. This is an example of one of the many times where information criteria give different answer since they penalise complexity in different ways. We can also double check the previous comments, and find out which neural network is the one with the smallest value for the cross-entropy loss function, by using the which.min command. which.min(c(nn_credit_one_layer$result.matrix[4,1], nn_credit_two_layers_1$result.matrix[4,1], nn_credit_two_layers_2$result.matrix[4,1], nn_credit_two_layers_3$result.matrix[4,1])) ## aic ## 4 which.min(c(nn_credit_one_layer$result.matrix[5,1], nn_credit_two_layers_1$result.matrix[5,1], nn_credit_two_layers_2$result.matrix[5,1], nn_credit_two_layers_3$result.matrix[5,1])) ## bic ## 3 which.min(c(nn_credit_one_layer$result.matrix[1,1], nn_credit_two_layers_1$result.matrix[1,1], nn_credit_two_layers_2$result.matrix[1,1], nn_credit_two_layers_3$result.matrix[1,1])) ## error ## 4 To predict on the test data, we need to first clean the data as for the training data. # Data pre-processing test &lt;- German_test test$Credit_amount &lt;- min_max_scale(test$Credit_amount) test$Creditability &lt;- as.integer(test$Creditability)-1 test_credit_card_matrix &lt;- model.matrix(~Account_balance+Purpose+Length_of_cur_employment +Credit_amount, data=test) test_credit_card_matrix_final &lt;- test_credit_card_matrix[,-1] # Prediction test_pred &lt;- predict(nn_credit_two_layers_3,test_credit_card_matrix_final) table(test$Creditability,test_pred&gt;0.5) ## ## FALSE TRUE ## 0 60 97 ## 1 78 265 "],["introduction-to-pytorch.html", "4 Introduction to PyTorch 4.1 Install PyTorch 4.2 What is PyTorch? 4.3 Basic computations on Tensors 4.4 Neural networks in PyTorch 4.5 Automatic Differentiation in PyTorch", " 4 Introduction to PyTorch Acknowledgement: Lab materials on PyTorch are developed on Software Lab 1 of MIT Introduction to Deep Learning. 4.1 Install PyTorch PyTorch is a popular deep learning library known for its flexibility and ease of use. Let's start by installing PyTorch. There are a few options to install and run PyTorch. Option 1: Install and run PyTorch locally. Depending on operating system (OS), Python version and availability of cuda-enabled GPUs, you can find the install command on https://pytorch.org/get-started/locally/ and install using pip. For example, on Windows OS with CPU only, the install command is: pip3 install torch torchvision torchaudio Option 2: Use Google Colab Another option for accessing free GPUs is by using Google Colab, which is an alternative to installing Python on your own computer. https://colab.research.google.com/ !pip3 install torch torchaudio torchvision torchtext torchdata You can verify if PyTorch is installed successfully by running: import torch print(torch.__version__) # Check version ## 2.6.0+cpu If it is successful, continue to load a couple of dependencies which will be useful for this lab. import torch.nn as nn import numpy as np import matplotlib.pyplot as plt 4.2 What is PyTorch? PyTorch is a machine learning library. At its core, PyTorch provides an interface for creating and manipulating tensors. A tensor is a multi-dimensional array where the number of dimensions is known as its rank. A rank-0 tensor is just a single number, or a scalar A rank-1 tensor is also called a vector A rank-2 tensor is also called a matrix PyTorch provides the ability to perform computation on these tensors, define neural networks, and train them efficiently. The shape of a PyTorch tensor defines its number of dimensions and the size of each dimension. The ndim or dim of a PyTorch tensor provides the number of dimensions (n-dimensions), and you can also think of this as the tensor's order or degree. Let's start by creating some tensors and inspecting their properties: integer = torch.tensor(1234) decimal = torch.tensor(3.14159265359) print(f&quot;`integer` is a {integer.ndim}-d Tensor: {integer}&quot;) ## `integer` is a 0-d Tensor: 1234 print(f&quot;`decimal` is a {decimal.ndim}-d Tensor: {decimal}&quot;) ## `decimal` is a 0-d Tensor: 3.1415927410125732 Vectors and lists can be used to create 1-d tensors: fibonacci = torch.tensor([1, 1, 2, 3, 5, 8]) count_to_100 = torch.tensor(range(100)) print(f&quot;`fibonacci` is a {fibonacci.ndim}-d Tensor with shape: {fibonacci.shape}&quot;) ## `fibonacci` is a 1-d Tensor with shape: torch.Size([6]) print(f&quot;`count_to_100` is a {count_to_100.ndim}-d Tensor with shape: {count_to_100.shape}&quot;) ## `count_to_100` is a 1-d Tensor with shape: torch.Size([100]) Next, letâ€™s create 2-d (i.e., matrices) and higher-rank tensors. In image processing and computer vision, we will use 4-d Tensors with dimensions corresponding to batch size, number of color channels, image height, and image width. ### Defining higher-order Tensors &#39;&#39;&#39;TODO: Define a 2-d Tensor&#39;&#39;&#39; matrix = # TODO assert isinstance(matrix, torch.Tensor), &quot;matrix must be a torch Tensor object&quot; assert matrix.ndim == 2 &#39;&#39;&#39;TODO: Define a 4-d Tensor.&#39;&#39;&#39; # Use torch.zeros to initialize a 4-d Tensor of zeros with size 10 x 3 x 256 x 256. # You can think of this as 10 images where each image is RGB 256 x 256. images = # TODO assert isinstance(images, torch.Tensor), &quot;images must be a torch Tensor object&quot; assert images.ndim == 4, &quot;images must have 4 dimensions&quot; assert images.shape == (10, 3, 256, 256), &quot;images is incorrect shape&quot; print(f&quot;images is a {images.ndim}-d Tensor with shape: {images.shape}&quot;) Solution matrix = torch.tensor([[1, 1, 1], [2,2,2]]) #An example of 2-d tensor images = torch.tensor(torch.zeros(10,3,256,256)) print(f&quot;images is a {images.ndim}-d Tensor with shape: {images.shape}&quot;) ## images is a 4-d Tensor with shape: torch.Size([10, 3, 256, 256]) As you have seen, the shape of a tensor provides the number of elements in each tensor dimension. The shape is quite useful, and we'll use it often. You can also use slicing to access subtensors within a higher-rank tensor: row_vector = matrix[1] column_vector = matrix[:, 1] scalar = matrix[0, 1] print(f&quot;`row_vector`: {row_vector}&quot;) ## `row_vector`: tensor([2, 2, 2]) print(f&quot;`column_vector`: {column_vector}&quot;) ## `column_vector`: tensor([1, 2]) print(f&quot;`scalar`: {scalar}&quot;) ## `scalar`: 1 4.3 Basic computations on Tensors Next we'll do some calculations. First, we'll create two tensors that have a constant value then add them together. a = torch.tensor(15) b = torch.tensor(61) # add the two constants together and print c1 = torch.add(a, b) c2 = a + b # PyTorch overrides the &quot;+&quot; operation so that it is able to act on Tensors print(f&quot;c1: {c1}&quot;) ## c1: 76 print(f&quot;c2: {c2}&quot;) ## c2: 76 We can repeat this exercise with rank-2 tensors now and also explore some other computations. # create constant tensors a = torch.tensor([[1, 2, 3],[4, 5, 6]]) b = torch.tensor([[6, 5, 4],[3, 2, 1]]) # add them together and print c1 = torch.add(a, b) print(f&quot;c1: {c1}&quot;) ## c1: tensor([[7, 7, 7], ## [7, 7, 7]]) # elementwise multiplication c2 = torch.multiply(a, b) print(f&quot;c2: {c2}&quot;) ## c2: tensor([[ 6, 10, 12], ## [12, 10, 6]]) 4.4 Neural networks in PyTorch We can also define neural networks in PyTorch. PyTorch uses torch.nn.Module, which serves as a base class for all neural network modules in PyTorch and thus provides a framework for building and training neural networks. Let's consider the example of a simple perceptron defined by just one dense (aka fully-connected or linear) layer: \\(y = \\sigma(Wx + b)\\), where \\(W\\) represents a matrix of weights, \\(b\\) is a bias, \\(x\\) is the input, \\(\\sigma\\) is the sigmoid activation function, and \\(y\\) is the output. In PyTorch, we define layers using torch.nn.Module, which provides a way to create and organise the building blocks of a neural network. To create a custom layer, we define a new class that is based on nn.Module. Inside this class, we specify the layer's parameters as attributes and implement a function called forward. The forward function defines how the input data is processed by this layer during the forward pass. Every time we create a new type of layer, we need to define what happens to the input in the forward function. This ensures that our layer performs the correct computation at each step of training or inference. Let's write a dense layer class to implement a perceptron defined above. ### Defining a dense layer # num_inputs: number of input nodes # num_outputs: number of output nodes # x: input to the layer class OurDenseLayer(torch.nn.Module): def __init__(self, num_inputs, num_outputs): super(OurDenseLayer, self).__init__() # Define and initialise parameters: a weight matrix W and bias b # Note that the parameter initialise is random! self.W = torch.nn.Parameter(torch.randn(num_inputs, num_outputs)) self.bias = torch.nn.Parameter(torch.randn(num_outputs)) def forward(self, x): &#39;&#39;&#39;TODO: define the operation for z (hint: use torch.matmul).&#39;&#39;&#39; z = # TODO &#39;&#39;&#39;TODO: define the operation for out (hint: use torch.sigmoid).&#39;&#39;&#39; y = # TODO return y Solution class OurDenseLayer(torch.nn.Module): def __init__(self, num_inputs, num_outputs): super(OurDenseLayer, self).__init__() self.W = torch.nn.Parameter(torch.randn(num_inputs, num_outputs)) self.bias = torch.nn.Parameter(torch.randn(num_outputs)) def forward(self, x): z = torch.matmul(x, self.W) + self.bias y = torch.sigmoid(z) return y Now, let's test the output of our layer. # Define a layer and test the output num_inputs = 2 num_outputs = 3 layer = OurDenseLayer(num_inputs, num_outputs) x_input = torch.tensor([[1, 2.]]) y = layer(x_input) print(f&quot;input shape: {x_input.shape}&quot;) ## input shape: torch.Size([1, 2]) print(f&quot;output shape: {y.shape}&quot;) ## output shape: torch.Size([1, 3]) print(f&quot;output result: {y}&quot;) ## output result: tensor([[0.0028, 0.0084, 0.1328]], grad_fn=&lt;SigmoidBackward0&gt;) Conveniently, PyTorch has defined a number of nn.Modules (or Layers) that are commonly used in neural networks, for example a nn.Linear or nn.Sigmoid module. Now, instead of using a single Module to define our simple neural network, we'll use the nn.Sequential module from PyTorch and a single nn.Linear layer to define our network. With the Sequential API, you can readily create neural networks by stacking together layers like building blocks. ### Defining a neural network using the PyTorch Sequential API # define the number of inputs and outputs n_input_nodes = 2 n_output_nodes = 3 # Define the model &#39;&#39;&#39;TODO: Use the Sequential API to define a neural network with a single linear (dense!) layer, followed by non-linearity to compute z&#39;&#39;&#39; model = nn.Sequential( &#39;&#39;&#39; TODO &#39;&#39;&#39; ) Solution n_input_nodes = 2 n_output_nodes = 3 model = nn.Sequential( nn.Linear(n_input_nodes, n_output_nodes), nn.Sigmoid() ) We've defined our model using the Sequential API. Now, we can test it out using an example input: # Test the model with example input x_input = torch.tensor([[1, 2.]]) model_output = model(x_input) print(f&quot;input shape: {x_input.shape}&quot;) ## input shape: torch.Size([1, 2]) print(f&quot;output shape: {y.shape}&quot;) ## output shape: torch.Size([1, 3]) print(f&quot;output result: {y}&quot;) ## output result: tensor([[0.0028, 0.0084, 0.1328]], grad_fn=&lt;SigmoidBackward0&gt;) With PyTorch, we can create more flexible models by building on nn.Module (technically, it is known as subclass nn.Module, inheriting the properties and behaviors of the base class, i.e. nn.Module in this case). The nn.Module class allows us to group layers together flexibly to define new architectures. As we saw earlier with OurDenseLayer, we can subclass nn.Module to create a class for our model. Inside this class, we define the layers we need and specify how data moves through them using the forward function. This approach gives us the flexibility to create custom layers, custom training loops, custom activation functions, and entirely new model architectures. Let's define the same neural network model as above (i.e., Linear layer with an activation function after it), now using a class-based approach and PyTorch's built-in linear layer from nn.Linear. ### Defining a model using subclassing class LinearWithSigmoidActivation(nn.Module): def __init__(self, num_inputs, num_outputs): super(LinearWithSigmoidActivation, self).__init__() &#39;&#39;&#39;TODO: define a model with a single Linear layer and sigmoid activation.&#39;&#39;&#39; self.linear = &#39;&#39;&#39;TODO: linear layer&#39;&#39;&#39; self.activation = &#39;&#39;&#39;TODO: sigmoid activation&#39;&#39;&#39; def forward(self, inputs): linear_output = self.linear(inputs) output = self.activation(linear_output) return output Solution class LinearWithSigmoidActivation(nn.Module): def __init__(self, num_inputs, num_outputs): super(LinearWithSigmoidActivation, self).__init__() self.linear = nn.Linear(num_inputs, num_outputs) self.activation = nn.Sigmoid() def forward(self, inputs): linear_output = self.linear(inputs) output = self.activation(linear_output) return output Let's test out our new model, using an example input, setting n_input_nodes=2 and n_output_nodes=3 as before. n_input_nodes = 2 n_output_nodes = 3 model = LinearWithSigmoidActivation(n_input_nodes, n_output_nodes) x_input = torch.tensor([[1, 2.]]) y = model(x_input) print(f&quot;input shape: {x_input.shape}&quot;) ## input shape: torch.Size([1, 2]) print(f&quot;output shape: {y.shape}&quot;) ## output shape: torch.Size([1, 3]) print(f&quot;output result: {y}&quot;) ## output result: tensor([[0.6359, 0.8195, 0.0851]], grad_fn=&lt;SigmoidBackward0&gt;) 4.5 Automatic Differentiation in PyTorch In PyTorch, torch.autograd is used for automatic differentiation, which is critical for training deep learning models with backpropagation. We will use the PyTorch .backward() method to trace operations for computing gradients. On a tensor, the requires_grad attribute controls whether autograd should record operations on that tensor. When a forward pass is made through the network, PyTorch records all the operations that occur; then, to compute the gradient, the backward() method is called to perform backpropagation. Let's compute the gradient of \\(y = x^2\\): ### Gradient computation # y = x^2 # Example: x = 3.0 x = torch.tensor(3.0, requires_grad=True) y = x ** 2 y.backward() # Compute the gradient dy_dx = x.grad print(&quot;dy_dx of y=x^2 at x=3.0 is: &quot;, dy_dx) ## dy_dx of y=x^2 at x=3.0 is: tensor(6.) assert dy_dx == 6.0 In training neural networks, we use differentiation and stochastic gradient descent (SGD) to optimise a loss function. Now that we have a sense of how PyTorch's autograd can be used to compute and access derivatives, we will look at an example where we use automatic differentiation and SGD to find the minimum of \\(L=(x-x_f)^2\\). Here \\(x_f\\) is a variable for a desired value we are trying to optimize for; \\(L\\) represents a loss that we are trying to minimize. While we can clearly solve this problem analytically (\\(x_{min}=x_f\\)), considering how we can compute this using PyTorch's autograd sets us up nicely for future activities where we use gradient descent to optimise entire neural network losses. ### Function minimization with autograd and gradient descent # Initialize a random value for our intial x x = torch.randn(1) print(f&quot;Initializing x={x.item()}&quot;) learning_rate = 1e-2 # Learning rate history = [] x_f = 4 # Target value # We will run gradient descent for a number of iterations. At each iteration, we compute the loss, # compute the derivative of the loss with respect to x, and perform the update. for i in range(500): x = torch.tensor([x], requires_grad=True) # TODO: Compute the loss as the square of the difference between x and x_f loss = # TODO # Backpropagate through the loss to compute gradients loss.backward() # Update x with gradient descent x = x.item() - learning_rate * x.grad history.append(x.item()) # Plot the evolution of x as we optimize toward x_f plt.plot(history) plt.plot([0, 500], [x_f, x_f]) plt.legend((&#39;Predicted&#39;, &#39;True&#39;)) plt.xlabel(&#39;Iteration&#39;) plt.ylabel(&#39;x value&#39;) plt.show() Solution # Initialize a random value for our intial x x = torch.randn(1) print(f&quot;Initializing x={x.item()}&quot;) ## Initializing x=0.23929740488529205 learning_rate = 1e-2 # Learning rate history = [] x_f = 4 # Target value for i in range(500): x = torch.tensor([x], requires_grad=True) # Compute the loss as the square of the difference between x and x_f loss = (x-x_f) ** 2 # Backpropagate through the loss to compute gradients loss.backward() # Update x with gradient descent x = x.item() - learning_rate * x.grad history.append(x.item()) # Plot the evolution of x as we optimize toward x_f plt.plot(history) plt.plot([0, 500], [x_f, x_f]) plt.legend((&#39;Predicted&#39;, &#39;True&#39;)) plt.xlabel(&#39;Iteration&#39;) plt.ylabel(&#39;x value&#39;) plt.show() Now, we have covered the fundamental concepts of PyTorch - tensors, operations, neural networks, and automatic differentiation. "],["exercise-3-dividend-data.html", "5 Exercise 3: Dividend data Neural Networks in R Neural Networks in PyTorch", " 5 Exercise 3: Dividend data In this example, our goal is to develop a neural network to determine if a stock pays a dividend or not. The dataset is stored under dividendinfo.csv, which includes one response variable and five predictor variables. dividend (class): A value of 1 indicates that the stock pays a dividend; 0 indicates that the stock that does not pay a dividend. fcfps: Free cash flow per share (in $) earnings_growth: Earnings growth in the past year (in %) de: Debt to Equity ratio mcap: Market Capitalization of the stock current_ratio: Current Ratio (or Current Assets/Current Liabilities) Neural Networks in R Task Read in the data and perform exploratory analysis. What have you observed? Solution dividend &lt;- read.csv(&quot;dividendinfo.csv&quot;) # some example codes for numerical summaries summary(dividend) library(skimr) skim(dividend) # some example codes for graphical summaries pairs(dividend) libray(GGally) ggpairs(dividend) par(mfrow=c(3,2)); invisible(lapply(2:ncol(dividend),function(i) boxplot(dividend[,i]~dividend$dividend))) Pre-process and split the data to prepare for training and evaluating a neural network. Hint As all variables are continuous and they have quite different ranges, scale them either using standardisation or min-max normalisation. Solution While there are built-in functions such as scale to standardise the entire data, the best practice is to split the data into training and test first and then apply standardisation/normalisation. This could avoid information leakage from training to test data. # Data split set.seed(1) idx &lt;- sample(nrow(dividend),0.8*nrow(dividend)) train &lt;- dividend[idx,] test &lt;- dividend[-idx,] # option 1: Standardise the data means &lt;- apply(train[,2:6], 2, mean) sds &lt;- apply(train[,2:6], 2, sd) train.std &lt;- scale(train[,2:6]) train.std &lt;- data.frame(cbind(train[,1],train.std)) test.std &lt;- scale(test[,2:6], means, sds) test.std &lt;- data.frame(cbind(test[,1],test.std)) colnames(train.std) &lt;- colnames(train) colnames(test.std) &lt;- colnames(test) # option 2: Normalise the data min_max_scale_test &lt;- function(x_tr, x_te){ mins &lt;- apply(x_tr, 2, min) maxs &lt;- apply(x_tr, 2, max) x_te &lt;- rbind(mins,maxs, x_te) x_te &lt;- apply(x_te, 2, function(x) (x-x[1])/(x[2]-x[1])) x_te &lt;- x_te[-c(1:2),] } train.norm &lt;-apply(train[,2:6], 2, function(x) (x-min(x))/(max(x)-min(x)) ) train.norm &lt;-data.frame(cbind(train[,1],train.norm)) test.norm &lt;-min_max_scale_test(train[,2:6], test[,2:6]) test.norm &lt;-data.frame(cbind(test[,1], test.norm)) colnames(train.norm) &lt;- colnames(train) colnames(test.norm) &lt;- colnames(test) Build a neural network with a single hidden layer, any number of hidden nodes, and the logistic function as the activation function. Interpret the relative importance of variables using the garson function. Solution set.seed(1) nn_di &lt;- neuralnet(dividend~., data=train.std, hidden=c(5), err.fct=&quot;ce&quot;, act.fct=&quot;logistic&quot;, linear.output=FALSE, likelihood=TRUE) garson(nn_di) We can see that the variable current_ratio is the one with the strongest relationship with the response variable dividend, followed by de, fcfps and mcap. The variable earnings_growth has the least relationship with dividend. Fit the above model multiple times using the argument rep and select the optimal model. Solution set.seed(1) nn_di &lt;- neuralnet(dividend~., data=train.std, hidden=c(5), err.fct=&quot;ce&quot;, act.fct=&quot;logistic&quot;, linear.output=FALSE, likelihood=TRUE, rep=5) # plot(nn_di) plot(nn_di, rep=&quot;best&quot;) From the plots (plot(nn_di)), we can see that the optimisation algorithm stops at different iterations (from Steps) and lead to differnt cross-entropy loss (from Error). In general, training the network longer decreases the cross-entropy loss. However, this decrease takes place on the training data set and may not generalise to the test. In other words, training the model longer may increase the risk of overfitting. To select the optimal model, we could look at the AIC and BIC values. which.min(nn_di$result.matrix[4,]) #AIC ## [1] 3 which.min(nn_di$result.matrix[5,]) #AIC ## [1] 3 AIC and BIC agree in this case and they both choose the third repetition. Evaluate the classification performance. Solution # Prediction train_pred &lt;- predict(nn_di, train.std) print(table(train.std$dividend, train_pred&gt;0.5)) ## ## FALSE TRUE ## 0 77 0 ## 1 0 83 test_pred &lt;- predict(nn_di, test.std) print(table(test.std$dividend, test_pred&gt;0.5)) ## ## FALSE TRUE ## 0 18 3 ## 1 1 18 Neural Networks in PyTorch Let's try to complete the previous tasks in Python and PyTorch. Load the data, pre-process it and split the data into training and test sets. Solution import pandas as pd from sklearn.preprocessing import StandardScaler, MinMaxScaler import torch.optim as optim dividend = pd.read_csv(&quot;dividendinfo.csv&quot;) dividend.iloc[:,1:6] = dividend.iloc[:,1:6].astype(np.float64) np.random.seed(1) # Data split idx = np.random.choice(dividend.index, size=int(0.8 * len(dividend)), replace=False) train = dividend.loc[idx] test = dividend.drop(idx) # Option 1: Standardise the data scaler = StandardScaler() train_std = train.copy() train_std.iloc[:, 1:6] = scaler.fit_transform(train.iloc[:, 1:6]) # Fit on the training data and transform it test_std = test.copy() test_std.iloc[:, 1:6] = scaler.transform(test.iloc[:, 1:6]) # Use the training data&#39;s parameters to standardise the test data # Option 2: Normalise the data scaler_norm = MinMaxScaler() train_norm = train.copy() train_norm.iloc[:, 1:6] = scaler_norm.fit_transform(train.iloc[:, 1:6]) test_norm = test.copy() test_norm.iloc[:, 1:6] = scaler_norm.transform(test.iloc[:, 1:6]) Use the Sequential API or subclass nn.Module to build a single-layer perceptron with logistic/sigmoid activation function for the hidden and output layers. Solution Use the Sequential API: model = nn.Sequential( nn.Linear(5, 5), # 5 input features -&gt; 5 hidden nodes nn.Sigmoid(), nn.Linear(5,1), # 5 hidden nodes -&gt; 1 output (for binary classification) nn.Sigmoid() ) Use the nn.Module: class SingleLayer(nn.Module): def __init__(self): super(SingleLayer, self).__init__() self.linear = nn.Linear(5, 5) # 5 input features -&gt; 5 hidden nodes self.activation = nn.Sigmoid() self.classifier = nn.Linear(5, 1) # 5 hidden nodes -&gt; 1 output (for binary classification) def forward(self, inputs): x = self.linear(inputs) # pass through hidden layer x = self.activation(x) # apply sigmoid activation x = self.classifier(x) # output layer x = self.activation(x) # apply sigmoid to output return x model = SingleLayer() Next, let's train the model. Since this is a binary classification task, we use the binary cross-entropy loss as our loss function. We will also need to define our training operation -- the optimizer and duration of training -- and use this to train the model. More details on this will be explained in Week 9 lecture note and lab. # Convert from dataframe to tensor X_tensor = torch.tensor(train_std.iloc[:, 1:6].values, dtype=torch.float32) y_tensor = torch.tensor(train_std.iloc[:, 0].values, dtype=torch.float32).view(-1, 1) X_test_tensor = torch.tensor(test_std.iloc[:, 1:6].values, dtype=torch.float32) y_test_tensor = torch.tensor(test_std.iloc[:, 0].values, dtype=torch.float32).view(-1,1) # Specify loss function and optimizer criterion = nn.BCELoss() optimizer = optim.SGD(model.parameters(), lr=0.1) num_epochs = 1000 history = [] for epoch in range(num_epochs): # Zero the gradients optimizer.zero_grad() # Forward pass y = model(X_tensor) # Compute the loss between the predictions and the targets loss = criterion(y, y_tensor) # Backpropagate through the loss to compute gradients loss.backward() # Update x with gradient descent optimizer.step() history.append(loss.item()) plt.plot(history) plt.show() Finally, we can use our trained neural network for prediction. model.eval() # Set the model to evaluation mode ## SingleLayer( ## (linear): Linear(in_features=5, out_features=5, bias=True) ## (activation): Sigmoid() ## (classifier): Linear(in_features=5, out_features=1, bias=True) ## ) with torch.no_grad(): # Disable gradient computation during prediction y_pred = model(X_tensor) y_test_pred = model(X_test_tensor) y_pred_binary = (y_pred &gt;= 0.5).float() # Threshold at 0.5 to get binary predictions y_test_pred_binary = (y_test_pred &gt;= 0.5).float() # Threshold at 0.5 to get binary predictions # Calculate accuracy correct_predictions = (y_pred_binary == y_tensor) train_accuracy = correct_predictions.sum().item() / y_tensor.shape[0] # Training accuracy correct_predictions = (y_test_pred_binary == y_test_tensor) test_accuracy = correct_predictions.sum().item() / y_test_tensor.shape[0] # Training accuracy print(f&#39;Training accuracy: {train_accuracy * 100:.2f}%, Test accuracy: {test_accuracy * 100:.2f}%&#39;) ## Training accuracy: 96.25%, Test accuracy: 92.50% "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
